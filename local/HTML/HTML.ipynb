{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/landonwiedenman/.pyenv/versions/3.6.3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Embedding, TimeDistributed, RepeatVector, LSTM, concatenate , Input, Reshape, Dense, Flatten\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images and preprocess them for inception-resnet\n",
    "images = []\n",
    "all_filenames = listdir('images/')\n",
    "all_filenames.sort()\n",
    "for filename in all_filenames:\n",
    "    images.append(img_to_array(load_img('images/'+filename, target_size=(299, 299))))\n",
    "images = np.array(images, dtype=float)\n",
    "images = preprocess_input(images)\n",
    "\n",
    "# Run the images through inception-resnet and extract the features without the classification layer\n",
    "IR2 = InceptionResNetV2(weights='imagenet', include_top=False)\n",
    "features = IR2.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will cap each input sequence to 100 tokens\n",
    "max_caption_len = 100\n",
    "# Initialize the function that will create our vocabulary \n",
    "tokenizer = Tokenizer(filters='', split=\" \", lower=False)\n",
    "\n",
    "# Read a document and return a string\n",
    "def load_doc(filename):\n",
    "    file = open(filename, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# Load all the HTML files\n",
    "X = []\n",
    "all_filenames = listdir('html/')\n",
    "all_filenames.sort()\n",
    "for filename in all_filenames:\n",
    "    X.append(load_doc('html/'+filename))\n",
    "\n",
    "# Create the vocabulary from the html files\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "# Add +1 to leave space for empty words\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "# Translate each word in text file to the matching vocabulary index\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "# The longest HTML file\n",
    "max_length = max(len(s) for s in sequences)\n",
    "\n",
    "# Intialize our final input to the model\n",
    "X, y, image_data = list(), list(), list()\n",
    "for img_no, seq in enumerate(sequences):\n",
    "    for i in range(1, len(seq)):\n",
    "        # Add the entire sequence to the input and only keep the next word for the output\n",
    "        in_seq, out_seq = seq[:i], seq[i]\n",
    "        # If the sentence is shorter than max_length, fill it up with empty words\n",
    "        in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "        # Map the output to one-hot encoding\n",
    "        out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "        # Add and image corresponding to the HTML file\n",
    "        image_data.append(features[img_no])\n",
    "        # Cut the input sentence to 100 tokens, and add it to the input data\n",
    "        X.append(in_seq[-100:])\n",
    "        y.append(out_seq)\n",
    "\n",
    "X, y, image_data = np.array(X), np.array(y), np.array(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the encoder\n",
    "image_features = Input(shape=(8, 8, 1536,))\n",
    "image_flat = Flatten()(image_features)\n",
    "image_flat = Dense(128, activation='relu')(image_flat)\n",
    "ir2_out = RepeatVector(max_caption_len)(image_flat)\n",
    "\n",
    "language_input = Input(shape=(max_caption_len,))\n",
    "language_model = Embedding(vocab_size, 200, input_length=max_caption_len)(language_input)\n",
    "language_model = LSTM(256, return_sequences=True)(language_model)\n",
    "language_model = LSTM(256, return_sequences=True)(language_model)\n",
    "language_model = TimeDistributed(Dense(128, activation='relu'))(language_model)\n",
    "\n",
    "# Create the decoder\n",
    "decoder = concatenate([ir2_out, language_model])\n",
    "decoder = LSTM(512, return_sequences=False)(decoder)\n",
    "decoder_output = Dense(vocab_size, activation='softmax')(decoder)\n",
    "\n",
    "# Compile the model\n",
    "model = Model(inputs=[image_features, language_input], outputs=decoder_output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/750\n",
      "2306/2306 [==============================] - 58s 25ms/step - loss: 5.9050\n",
      "Epoch 2/750\n",
      "2306/2306 [==============================] - 61s 27ms/step - loss: 5.7501\n",
      "Epoch 3/750\n",
      "2306/2306 [==============================] - 58s 25ms/step - loss: 5.7027\n",
      "Epoch 4/750\n",
      "2306/2306 [==============================] - 56s 24ms/step - loss: 5.7247\n",
      "Epoch 5/750\n",
      "2306/2306 [==============================] - 57s 25ms/step - loss: 5.6924\n",
      "Epoch 6/750\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 5.6940\n",
      "Epoch 7/750\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 5.6944\n",
      "Epoch 8/750\n",
      "2306/2306 [==============================] - 57s 25ms/step - loss: 5.7029\n",
      "Epoch 9/750\n",
      "2306/2306 [==============================] - 57s 25ms/step - loss: 5.7002\n",
      "Epoch 10/750\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 5.6863\n",
      "Epoch 11/750\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 5.6652\n",
      "Epoch 12/750\n",
      "2306/2306 [==============================] - 58s 25ms/step - loss: 5.6508\n",
      "Epoch 13/750\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 5.6503\n",
      "Epoch 14/750\n",
      "2306/2306 [==============================] - 59s 26ms/step - loss: 5.6542\n",
      "Epoch 15/750\n",
      "2306/2306 [==============================] - 77s 34ms/step - loss: 5.6368\n",
      "Epoch 16/750\n",
      "2306/2306 [==============================] - 93s 40ms/step - loss: 5.6230\n",
      "Epoch 17/750\n",
      "2306/2306 [==============================] - 53s 23ms/step - loss: 5.6210\n",
      "Epoch 18/750\n",
      "2306/2306 [==============================] - 51s 22ms/step - loss: 5.5832\n",
      "Epoch 19/750\n",
      "2306/2306 [==============================] - 51s 22ms/step - loss: 5.5696\n",
      "Epoch 20/750\n",
      "2306/2306 [==============================] - 51s 22ms/step - loss: 5.5519\n",
      "Epoch 21/750\n",
      "2306/2306 [==============================] - 51s 22ms/step - loss: 5.5649\n",
      "Epoch 22/750\n",
      "2306/2306 [==============================] - 51s 22ms/step - loss: 5.5391\n",
      "Epoch 23/750\n",
      "2306/2306 [==============================] - 51s 22ms/step - loss: 5.5668\n",
      "Epoch 24/750\n",
      "2306/2306 [==============================] - 51s 22ms/step - loss: 5.5515\n",
      "Epoch 25/750\n",
      "2306/2306 [==============================] - 51s 22ms/step - loss: 5.5424\n",
      "Epoch 26/750\n",
      "2306/2306 [==============================] - 51s 22ms/step - loss: 5.5391\n",
      "Epoch 27/750\n",
      "2306/2306 [==============================] - 51s 22ms/step - loss: 5.5269\n",
      "Epoch 28/750\n",
      "2306/2306 [==============================] - 51s 22ms/step - loss: 5.5151\n",
      "Epoch 29/750\n",
      "2306/2306 [==============================] - 51s 22ms/step - loss: 5.4845\n",
      "Epoch 30/750\n",
      "2306/2306 [==============================] - 51s 22ms/step - loss: 5.4818\n",
      "Epoch 31/750\n",
      "2306/2306 [==============================] - 51s 22ms/step - loss: 5.4868\n",
      "Epoch 32/750\n",
      "2306/2306 [==============================] - 50s 21ms/step - loss: 5.5055\n",
      "Epoch 33/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.5155\n",
      "Epoch 34/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.5072\n",
      "Epoch 35/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.5320\n",
      "Epoch 36/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.5467\n",
      "Epoch 37/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.5310\n",
      "Epoch 38/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.5132\n",
      "Epoch 39/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.4953\n",
      "Epoch 40/750\n",
      "2306/2306 [==============================] - 54s 24ms/step - loss: 5.4782\n",
      "Epoch 41/750\n",
      "2306/2306 [==============================] - 52s 23ms/step - loss: 5.4721\n",
      "Epoch 42/750\n",
      "2306/2306 [==============================] - 54s 23ms/step - loss: 5.4470\n",
      "Epoch 43/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.4504\n",
      "Epoch 44/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.4626\n",
      "Epoch 45/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.4644\n",
      "Epoch 46/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.4685\n",
      "Epoch 47/750\n",
      "2306/2306 [==============================] - 50s 22ms/step - loss: 5.4482\n",
      "Epoch 48/750\n",
      "2306/2306 [==============================] - 50s 22ms/step - loss: 5.4608\n",
      "Epoch 49/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.4441\n",
      "Epoch 50/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.4440\n",
      "Epoch 51/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.4220\n",
      "Epoch 52/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.4061\n",
      "Epoch 53/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.4157\n",
      "Epoch 54/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.4265\n",
      "Epoch 55/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.4045\n",
      "Epoch 56/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.4004\n",
      "Epoch 57/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.4013\n",
      "Epoch 58/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3677\n",
      "Epoch 59/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.4019\n",
      "Epoch 60/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3744\n",
      "Epoch 61/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3898\n",
      "Epoch 62/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3662\n",
      "Epoch 63/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3785\n",
      "Epoch 64/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3472\n",
      "Epoch 65/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3337\n",
      "Epoch 66/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3914\n",
      "Epoch 67/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.4077\n",
      "Epoch 68/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.3429\n",
      "Epoch 69/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3584\n",
      "Epoch 70/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3784\n",
      "Epoch 71/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3499\n",
      "Epoch 72/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3390\n",
      "Epoch 73/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3230\n",
      "Epoch 74/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3435\n",
      "Epoch 75/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3384\n",
      "Epoch 76/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3500\n",
      "Epoch 77/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3665\n",
      "Epoch 78/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3481\n",
      "Epoch 79/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3325\n",
      "Epoch 80/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3416\n",
      "Epoch 81/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3907\n",
      "Epoch 82/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3564\n",
      "Epoch 83/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3310\n",
      "Epoch 84/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.3203\n",
      "Epoch 85/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3374\n",
      "Epoch 86/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.3473\n",
      "Epoch 87/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3340\n",
      "Epoch 88/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3254\n",
      "Epoch 89/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.3193\n",
      "Epoch 90/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3143\n",
      "Epoch 91/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.3099\n",
      "Epoch 92/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.3060\n",
      "Epoch 93/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.3024\n",
      "Epoch 94/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2991\n",
      "Epoch 95/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2961\n",
      "Epoch 96/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2933\n",
      "Epoch 97/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2907\n",
      "Epoch 98/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2882\n",
      "Epoch 99/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2860\n",
      "Epoch 100/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2838\n",
      "Epoch 101/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2818\n",
      "Epoch 102/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2800\n",
      "Epoch 103/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2782\n",
      "Epoch 104/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2766\n",
      "Epoch 105/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2751\n",
      "Epoch 106/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2736\n",
      "Epoch 107/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2722\n",
      "Epoch 108/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2709\n",
      "Epoch 109/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2697\n",
      "Epoch 110/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2685\n",
      "Epoch 111/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2674\n",
      "Epoch 112/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2664\n",
      "Epoch 113/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2654\n",
      "Epoch 114/750\n",
      "2306/2306 [==============================] - 53s 23ms/step - loss: 5.2645\n",
      "Epoch 115/750\n",
      "2306/2306 [==============================] - 52s 23ms/step - loss: 5.2636\n",
      "Epoch 116/750\n",
      "2306/2306 [==============================] - 53s 23ms/step - loss: 5.2627\n",
      "Epoch 117/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2619\n",
      "Epoch 118/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2611\n",
      "Epoch 119/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2604\n",
      "Epoch 120/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2597\n",
      "Epoch 121/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2590\n",
      "Epoch 122/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2584\n",
      "Epoch 123/750\n",
      "2306/2306 [==============================] - 50s 22ms/step - loss: 5.2578\n",
      "Epoch 124/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2572\n",
      "Epoch 125/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2566\n",
      "Epoch 126/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2561\n",
      "Epoch 127/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2556\n",
      "Epoch 128/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2551\n",
      "Epoch 129/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2546\n",
      "Epoch 130/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2542\n",
      "Epoch 131/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2538\n",
      "Epoch 132/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2533\n",
      "Epoch 133/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2529\n",
      "Epoch 134/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2526\n",
      "Epoch 135/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2522\n",
      "Epoch 136/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2518\n",
      "Epoch 137/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2515\n",
      "Epoch 138/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2512\n",
      "Epoch 139/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2508\n",
      "Epoch 140/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2505\n",
      "Epoch 141/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2502\n",
      "Epoch 142/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2500\n",
      "Epoch 143/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2497\n",
      "Epoch 144/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2494\n",
      "Epoch 145/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2492\n",
      "Epoch 146/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2489\n",
      "Epoch 147/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2487\n",
      "Epoch 148/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2485\n",
      "Epoch 149/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2482\n",
      "Epoch 150/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2480\n",
      "Epoch 151/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2478\n",
      "Epoch 152/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2476\n",
      "Epoch 153/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2474\n",
      "Epoch 154/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2472\n",
      "Epoch 155/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2470\n",
      "Epoch 156/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2469\n",
      "Epoch 157/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2467\n",
      "Epoch 158/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2465\n",
      "Epoch 159/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2464\n",
      "Epoch 160/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2462\n",
      "Epoch 161/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2460\n",
      "Epoch 162/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2459\n",
      "Epoch 163/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2458\n",
      "Epoch 164/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2456\n",
      "Epoch 165/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2455\n",
      "Epoch 166/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2453\n",
      "Epoch 167/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2452\n",
      "Epoch 168/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2451\n",
      "Epoch 169/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2450\n",
      "Epoch 170/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2449\n",
      "Epoch 171/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2447\n",
      "Epoch 172/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2446\n",
      "Epoch 173/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2445\n",
      "Epoch 174/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2444\n",
      "Epoch 175/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2443\n",
      "Epoch 176/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2442\n",
      "Epoch 177/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2441\n",
      "Epoch 178/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2440\n",
      "Epoch 179/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2439\n",
      "Epoch 180/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2438\n",
      "Epoch 181/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2437\n",
      "Epoch 182/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2437\n",
      "Epoch 183/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2436\n",
      "Epoch 184/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2435\n",
      "Epoch 185/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2434\n",
      "Epoch 186/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2433\n",
      "Epoch 187/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2433\n",
      "Epoch 188/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2306/2306 [==============================] - 51s 22ms/step - loss: 5.2432\n",
      "Epoch 189/750\n",
      "2306/2306 [==============================] - 52s 22ms/step - loss: 5.2431\n",
      "Epoch 190/750\n",
      "2306/2306 [==============================] - 53s 23ms/step - loss: 5.2430\n",
      "Epoch 191/750\n",
      "2306/2306 [==============================] - 51s 22ms/step - loss: 5.2430\n",
      "Epoch 192/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2429\n",
      "Epoch 193/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2428\n",
      "Epoch 194/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2428\n",
      "Epoch 195/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2427\n",
      "Epoch 196/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2426\n",
      "Epoch 197/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2426\n",
      "Epoch 198/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2425\n",
      "Epoch 199/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2425\n",
      "Epoch 200/750\n",
      "2306/2306 [==============================] - 51s 22ms/step - loss: 5.2424\n",
      "Epoch 201/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2424\n",
      "Epoch 202/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2423\n",
      "Epoch 203/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2423\n",
      "Epoch 204/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2422\n",
      "Epoch 205/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2422\n",
      "Epoch 206/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2421\n",
      "Epoch 207/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2421\n",
      "Epoch 208/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2420\n",
      "Epoch 209/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2420\n",
      "Epoch 210/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2419\n",
      "Epoch 211/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2419\n",
      "Epoch 212/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2418\n",
      "Epoch 213/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2418\n",
      "Epoch 214/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2417\n",
      "Epoch 215/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2417\n",
      "Epoch 216/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2417\n",
      "Epoch 217/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2416\n",
      "Epoch 218/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2416\n",
      "Epoch 219/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2415\n",
      "Epoch 220/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2415\n",
      "Epoch 221/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2415\n",
      "Epoch 222/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2414\n",
      "Epoch 223/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2414\n",
      "Epoch 224/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2414\n",
      "Epoch 225/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2413\n",
      "Epoch 226/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2413\n",
      "Epoch 227/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2413\n",
      "Epoch 228/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2412\n",
      "Epoch 229/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2412\n",
      "Epoch 230/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2412\n",
      "Epoch 231/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2411\n",
      "Epoch 232/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2411\n",
      "Epoch 233/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2411\n",
      "Epoch 234/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2411\n",
      "Epoch 235/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2410\n",
      "Epoch 236/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2410\n",
      "Epoch 237/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2410\n",
      "Epoch 238/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2409\n",
      "Epoch 239/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2409\n",
      "Epoch 240/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2409\n",
      "Epoch 241/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2409\n",
      "Epoch 242/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2408\n",
      "Epoch 243/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2408\n",
      "Epoch 244/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2408\n",
      "Epoch 245/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2408\n",
      "Epoch 246/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2407\n",
      "Epoch 247/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2407\n",
      "Epoch 248/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2407\n",
      "Epoch 249/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2407\n",
      "Epoch 250/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2407\n",
      "Epoch 251/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2406\n",
      "Epoch 252/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2406\n",
      "Epoch 253/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2406\n",
      "Epoch 254/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2406\n",
      "Epoch 255/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2406\n",
      "Epoch 256/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2405\n",
      "Epoch 257/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2405\n",
      "Epoch 258/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2405\n",
      "Epoch 259/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2405\n",
      "Epoch 260/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2405\n",
      "Epoch 261/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2404\n",
      "Epoch 262/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2404\n",
      "Epoch 263/750\n",
      "2306/2306 [==============================] - 53s 23ms/step - loss: 5.2404\n",
      "Epoch 264/750\n",
      "2306/2306 [==============================] - 52s 22ms/step - loss: 5.2404\n",
      "Epoch 265/750\n",
      "2306/2306 [==============================] - 53s 23ms/step - loss: 5.2404\n",
      "Epoch 266/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2404\n",
      "Epoch 267/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2403\n",
      "Epoch 268/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2403\n",
      "Epoch 269/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2403\n",
      "Epoch 270/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2403\n",
      "Epoch 271/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2403\n",
      "Epoch 272/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2403\n",
      "Epoch 273/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2402\n",
      "Epoch 274/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2402\n",
      "Epoch 275/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2402\n",
      "Epoch 276/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2402\n",
      "Epoch 277/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2402\n",
      "Epoch 278/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2402\n",
      "Epoch 279/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2402\n",
      "Epoch 280/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2401\n",
      "Epoch 281/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2401\n",
      "Epoch 282/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2401\n",
      "Epoch 283/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2401\n",
      "Epoch 284/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2401\n",
      "Epoch 285/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2401\n",
      "Epoch 286/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2401\n",
      "Epoch 287/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2401\n",
      "Epoch 288/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2400\n",
      "Epoch 289/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2400\n",
      "Epoch 290/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2400\n",
      "Epoch 291/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2400\n",
      "Epoch 292/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2400\n",
      "Epoch 293/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2400\n",
      "Epoch 294/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2400\n",
      "Epoch 295/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2400\n",
      "Epoch 296/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2400\n",
      "Epoch 297/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2399\n",
      "Epoch 298/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2399\n",
      "Epoch 299/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2399\n",
      "Epoch 300/750\n",
      "2306/2306 [==============================] - 48s 21ms/step - loss: 5.2399\n",
      "Epoch 301/750\n",
      "2306/2306 [==============================] - 49s 21ms/step - loss: 5.2399\n",
      "Epoch 302/750\n",
      "2306/2306 [==============================] - 50s 22ms/step - loss: 5.2399\n",
      "Epoch 303/750\n",
      "2306/2306 [==============================] - 50s 22ms/step - loss: 5.2399\n",
      "Epoch 304/750\n",
      "2306/2306 [==============================] - 50s 22ms/step - loss: 5.2399\n",
      "Epoch 305/750\n",
      "2306/2306 [==============================] - 50s 22ms/step - loss: 5.2399\n",
      "Epoch 306/750\n",
      "2306/2306 [==============================] - 50s 22ms/step - loss: 5.2399\n",
      "Epoch 307/750\n",
      "1856/2306 [=======================>......] - ETA: 9s - loss: 5.1370 "
     ]
    }
   ],
   "source": [
    "# Train the neural network\n",
    "model.fit([image_data, X], y, batch_size=64, shuffle=False, epochs=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map an integer to a word\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a description for an image\n",
    "def generate_desc(model, tokenizer, photo, max_length):\n",
    "    # seed the generation process\n",
    "    in_text = 'START'\n",
    "    # iterate over the whole length of the sequence\n",
    "    for i in range(900):\n",
    "        # integer encode input sequence\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0][-100:]\n",
    "        # pad input\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        # predict next word\n",
    "        yhat = model.predict([photo,sequence], verbose=0)\n",
    "        # convert probability to integer\n",
    "        yhat = np.argmax(yhat)\n",
    "        # map integer to word\n",
    "        word = word_for_id(yhat, tokenizer)\n",
    "        # stop if we cannot map the word\n",
    "        if word is None:\n",
    "            break\n",
    "        # append as input for generating the next word\n",
    "        in_text += ' ' + word\n",
    "        # Print the prediction\n",
    "        print(' ' + word, end='')\n",
    "        # stop if we predict the end of the sequence\n",
    "        if word == 'END':\n",
    "            break\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and image, preprocess it for IR2, extract features and generate the HTML\n",
    "test_image = img_to_array(load_img('images/87.jpg', target_size=(299, 299)))\n",
    "test_image = np.array(test_image, dtype=float)\n",
    "test_image = preprocess_input(test_image)\n",
    "test_features = IR2.predict(np.array([test_image]))\n",
    "generate_desc(model, tokenizer, np.array(test_features), 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
